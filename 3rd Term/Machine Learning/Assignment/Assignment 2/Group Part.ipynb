{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\"> Assignment 2</div>\n",
    "## <div align=\"center\"> Machine Learning</div>\n",
    "### <div align=\"center\"> Group Assignment</div>\n",
    "\n",
    "\n",
    "<br><div align=\"center\"> By Group A3: </div>\n",
    "<div align=\"center\"> Jiaqi Chen, Yuxi Fu, Jiaxuan Lyu, Maria Tsotalou, Qian Zhang </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./\"\n",
    "\n",
    "# 1. loads the data file;\n",
    "training_data = pd.read_csv(data_path + 'training.csv') \n",
    "validation_data = pd.read_csv(data_path + 'validation.csv')\n",
    "test1_data = pd.read_csv(data_path + 'test1.csv') \n",
    "test2_data = pd.read_csv(data_path + 'test2.csv') \n",
    "\n",
    "# 2. load txt file\n",
    "text_file = open('censored_list_test1.txt', 'r')\n",
    "list_censored_test1 = text_file.read().split()\n",
    "text_file.close()\n",
    "\n",
    "text_file = open('censored_list_test2.txt', 'r')\n",
    "list_censored_test2 = text_file.read().split()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-157fedb014fc>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  col= col.str.replace('\\d+', ' ')\n",
      "<ipython-input-5-157fedb014fc>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  col = col.str.replace('[^\\w\\s]',' ')\n"
     ]
    }
   ],
   "source": [
    "def cleaning_sms(col):\n",
    "    # convert to lower-case\n",
    "    col = col.str.lower()\n",
    "    #remove digits\n",
    "    col= col.str.replace('\\d+', ' ')\n",
    "    #remove punctuation\n",
    "    col = col.str.replace('[^\\w\\s]',' ')\n",
    "    return col\n",
    "\n",
    "training_data[\"sms\"]   = cleaning_sms(training_data[\"sms\"])\n",
    "validation_data[\"sms\"] = cleaning_sms(validation_data[\"sms\"])\n",
    "test1_data[\"sms\"] = cleaning_sms(test1_data[\"sms\"])\n",
    "test2_data[\"sms\"] = cleaning_sms(test2_data[\"sms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam:\n",
    "#These two functions trains the  Naive Bayes classifier, i.e get the labeled SMS(messages for which we know whether they're spam or ham), \n",
    "#iterate over each individual message and identify\n",
    "\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    #Returning predictions, bayes's theorem is applied in this function \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:                                   \n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "#Calculating accuracy score and confusion matrix of the classifiers\n",
    "    def score (self, messages, labels):\n",
    "        ## | TP | FP |\n",
    "        ## | FN | TN |\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "#### The functions  above are used to calculate the posterior probability based on Naive Bayes theorem\n",
    "__train function__ \n",
    "* Creates a set of all the words present in the spam and ham messages\n",
    "* Calculates the frequency with each word is present in a sentence, this frequency represents the ratio of the times a spam/ham message contains such words. It is noted that this ratio is restricted to be lower than 0.95\n",
    "\n",
    "__train2 function__\n",
    " the function performs the same procedures as train 1 with the following differences\n",
    "* In train2 function a new list is generated named \"spamkeywords\", which contains letters with high probability to appear in spamMessage, actually those that appear more than 20 times more often in spam than in ham messages\n",
    "* Also, the likelihood calculation takes into account only the letters with high probability\n",
    "\n",
    "__predict function__\n",
    "* Initially all the words in the message are converted to lower case \n",
    "* Then the function uses the Naive Bayes method to calculate the posterior probability as a proportion of the likelihood and prior probability\n",
    "* After performing a normalisation, to deal with computational issues, the message is categorised as spam or ham according to the value of the posterior probability calculated\n",
    "\n",
    "__score function__\n",
    "* The function aggregates the number the messages based on whether they have been categorised correctly or wrongly . Essentialy it calculates and returns the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ham = list(training_data[training_data.label =='ham'].sms)\n",
    "training_spam = list(training_data[training_data.label =='spam'].sms)\n",
    "\n",
    "naive_bayes_training1=NaiveBayesForSpam()\n",
    "naive_bayes_training1.train(training_ham,training_spam)\n",
    "\n",
    "naive_bayes_training2=NaiveBayesForSpam()\n",
    "naive_bayes_training2.train2(training_ham,training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix1 = naive_bayes_training1.score(validation_data.sms, validation_data.label)\n",
    "confusion_matrix2 = naive_bayes_training2.score(validation_data.sms, validation_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate of classifer train is 0.958\n",
      "The accuracy rate of classifer train2 is 0.962\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy rate of classifer train is',confusion_matrix1[0])\n",
    "print('The accuracy rate of classifer train2 is',confusion_matrix2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of classifer train is:\n",
      "[[845.  27.]\n",
      " [ 15. 113.]]\n",
      "The Confusion Matrix of classifer train2 is:\n",
      "[[857.  35.]\n",
      " [  3. 105.]]\n"
     ]
    }
   ],
   "source": [
    "print('The Confusion Matrix of classifer train is:')\n",
    "print(confusion_matrix1[1])\n",
    "\n",
    "print('The Confusion Matrix of classifer train2 is:')\n",
    "print(confusion_matrix2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the 2nd classifier, which has been trained using the train2 function, has a higher accuracy rate. In more detail it gives more false positives and way less false negatives than the first classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "The train2 method is faster because it uses far less words in order to calculate the posterior probability, consequently the list of words with which we are comparing each word in the validation set is way shorter. As a resultfar less calculations are taking place, for example comparisons and multiplications. \n",
    "\n",
    "The train2 method is more accurate because it uses words that are 20+ times more often present in spam SMS messages than in ham messages. Consequently it is more probable to play an important role in the prediction process rather than the words that are ignored. \n",
    "Those \"non-important\" words might be misleading as it may cause noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we use the train classifier, there are 27.0 false positive.\n",
      "If we use the train2 classifier, there are 35.0 false positive.\n",
      "In order to reduce the number of false positives at the expense of false negatives we could decrease the limit at the threshold in the last part of  \"predict\" function at the line \"if posteriors[0] > 0.5:\" from 0.5 to a smaller number.\n"
     ]
    }
   ],
   "source": [
    "false_positives1 = confusion_matrix1[1][0][1]\n",
    "false_positives2 = confusion_matrix2[1][0][1]\n",
    "print('If we use the train classifier, there are',false_positives1,'false positive.')\n",
    "print('If we use the train2 classifier, there are',false_positives2,'false positive.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce the number of false positives at the expense of false negatives we could decrease the limit at the threshold in the last part of  \"predict\" function at the line \"if posteriors[0] > 0.5:\" from 0.5 to a smaller number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "We will ignore the missing variables when we predict the probability. Consequently this formula will become $P(Y = C_j | X_1 = x_1, ..., X_p = x_p) = P(Y = C_j | X_1 = x_1, ..., X_{j-1} = x_{j-1}, X_{k+1} = x_{k+1}, ..., X_p = x_p)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for list_censored_test1\n",
    "class NaiveBayesForSpam_updated_censored1:\n",
    "    #rewritten the class with changed the predict function:\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words) :\n",
    "            if (w not in list_censored_test1): # This algorithm ignores the censored that are included in test1.txt\n",
    "                if w in message.lower(): \n",
    "                    posteriors *= self.likelihoods[:,i]\n",
    "                else:                                   \n",
    "                    posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "                posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        ## | TP | FP |\n",
    "        ## | FN | TN |\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate of classifer train is\n",
      "0.97\n",
      "The accuracy rate of classifer train2 is 0.9727626459143969\n"
     ]
    }
   ],
   "source": [
    "training_ham = list(training_data[training_data.label =='ham'].sms)\n",
    "training_spam = list(training_data[training_data.label =='spam'].sms)\n",
    "\n",
    "#train test1:\n",
    "naive_bayes_test_censored1 = NaiveBayesForSpam_updated_censored1()\n",
    "naive_bayes_test_censored2 = NaiveBayesForSpam_updated_censored1()\n",
    "\n",
    "naive_bayes_test_censored1.train(training_ham, training_spam)\n",
    "naive_bayes_test_censored2.train2(training_ham, training_spam)\n",
    "\n",
    "confusion_matrix_test_censored1 = naive_bayes_test_censored1.score(test1_data.sms, test1_data.label)\n",
    "confusion_matrix_test_censored2 = naive_bayes_test_censored2.score(test1_data.sms, test1_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate of classifer train is 0.9681\n",
      "The accuracy rate of classifer train2 is 0.9728\n"
     ]
    }
   ],
   "source": [
    "accur1 = \"{:.4f}\".format(confusion_matrix_test_censored1[0])\n",
    "accur2 = \"{:.4f}\".format(confusion_matrix_test_censored2[0])\n",
    "\n",
    "print('The accuracy rate of classifer train is', accur1)\n",
    "print('The accuracy rate of classifer train2 is', accur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of classifer train is:\n",
      "[[1094.   25.]\n",
      " [  16.  150.]]\n",
      "The Confusion Matrix of classifer train2 is:\n",
      "[[1106.   31.]\n",
      " [   4.  144.]]\n"
     ]
    }
   ],
   "source": [
    "print('The Confusion Matrix of classifer train is:')\n",
    "print(confusion_matrix_test_censored1[1])\n",
    "\n",
    "print('The Confusion Matrix of classifer train2 is:')\n",
    "print(confusion_matrix_test_censored2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam_updated_censored2:\n",
    "    #rewritten the class with changed the predict function:\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if (w not in list_censored_test2): # This algorithm ignores the censored that are included in test2.txt\n",
    "                if w in message.lower(): \n",
    "                    posteriors *= self.likelihoods[:,i]\n",
    "                else:                                   \n",
    "                    posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "                posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        ## | TP | FP |\n",
    "        ## | FN | TN |\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ham = list(training_data[training_data.label =='ham'].sms)\n",
    "training_spam = list(training_data[training_data.label =='spam'].sms)\n",
    "\n",
    "#train test1:\n",
    "naive_bayes_test2_censored1 = NaiveBayesForSpam_updated_censored2()\n",
    "naive_bayes_test2_censored2 = NaiveBayesForSpam_updated_censored2()\n",
    "\n",
    "naive_bayes_test2_censored1.train(training_ham, training_spam)\n",
    "naive_bayes_test2_censored2.train2(training_ham, training_spam)\n",
    "\n",
    "confusion_matrix_test2_censored1 = naive_bayes_test2_censored1.score(test2_data.sms, test2_data.label)\n",
    "confusion_matrix_test2_censored2 = naive_bayes_test2_censored2.score(test2_data.sms, test2_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy rate of classifer train is 0.9666\n",
      "The accuracy rate of classifer train2 is 0.9611\n"
     ]
    }
   ],
   "source": [
    "accur_test2_1 = \"{:.4f}\".format(confusion_matrix_test2_censored1[0])\n",
    "accur_test2_2 = \"{:.4f}\".format(confusion_matrix_test2_censored2[0])\n",
    "\n",
    "print('The accuracy rate of classifer train is',accur_test2_1)\n",
    "print('The accuracy rate of classifer train2 is',accur_test2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix of classifer train is:\n",
      "[[1090.   31.]\n",
      " [  12.  153.]]\n",
      "The Confusion Matrix of classifer train2 is:\n",
      "[[1099.   47.]\n",
      " [   3.  137.]]\n"
     ]
    }
   ],
   "source": [
    "print('The Confusion Matrix of classifer train is:')\n",
    "print(confusion_matrix_test2_censored1[1])\n",
    "\n",
    "print('The Confusion Matrix of classifer train2 is:')\n",
    "print(confusion_matrix_test2_censored2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on test2 are slightly smaller than the accuracy on test1 but is still very high. This makes sense since 30% keywords for test2 are removed, while 10%keywords for test 1 are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: At this point we should mention that to achieve this result with a more \"beautiful\" and proper code we would create a sub-class of the NaiveBayesForSpam Class and override the predict method, having the censored_list as a conctructor variable for the derived class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
